---
sidebar_position: 1
description: Выполнить запрос и другие функции для работы с ClickHouse в Открытом пакете интеграций - бесплатной open-source библиотеке интеграций для 1С:Предприятие 8, OneScript и CLI
keywords: [1C, 1С, 1С:Предприятие, 1С:Предприятие 8.3, API, Интеграция, Сервисы, Обмен, OneScript, CLI, ClickHouse]
---

import Tabs from '@theme/Tabs';
import TabItem from '@theme/TabItem';

# Выполнить запрос
 Выполняет запрос с указанными параметрами



`Функция ВыполнитьЗапрос(Знач Соединение, Знач Запрос, Знач Сессия = Неопределено) Экспорт`

  | Параметр | CLI опция | Тип | Обяз. | Назначение |
  |-|-|-|-|-|
  | Соединение | --conn | Произвольный | &#x2714; | Настройки или объект соединения (для gRPC) |
  | Запрос | --req | Структура Из КлючИЗначение | &#x2714; | Данные запроса. См. [`ПолучитьНастройкиЗапроса`](/docs/ClickHouse/Common-methods/Get-request-settings) |
  | Сессия | --session | Структура Из КлючИЗначение | &#x2716; | Настройки сессии. См. [`ПолучитьНастройкиСессии`](/docs/ClickHouse/Common-methods/Get-session-settings) |

  
  Возвращаемое значение:   Соответствие Из КлючИЗначение - Результат выполнения



```bsl title="Пример использования для 1С:Предприятие/OneScript"
    // Настройки соединения

    URL = "http://localhost:8123";
    Логин  = "bayselonarrend";
    Пароль = "12we...";

    Авторизация = Новый Структура(Логин, Пароль);

    Соединение = OPI_ClickHouse.ПолучитьНастройкиСоединенияHTTP(URL, Авторизация);

    // Запрос (создание таблицы)

    ТекстЗапроса = "CREATE TABLE IF NOT EXISTS events (
    |    id UInt64,
    |    timestamp DateTime,
    |    user_id UInt32,
    |    event_type String,
    |    payload String
    |) ENGINE    = MergeTree()
    |ORDER BY (timestamp, id)";

    Запрос    = OPI_ClickHouse.ПолучитьНастройкиЗапроса(ТекстЗапроса);
    Результат = OPI_ClickHouse.ВыполнитьЗапрос(Соединение, Запрос);

    // Запрос (вставка данных)

    ТекстЗапроса = "INSERT INTO events FORMAT JSON";

    ФорматДанных = "JSON";
    МассивДанных = Новый Массив;

    ТекущаяДата = Дата("20260101100000");

    Запись1 = Новый Структура;
    Запись1.Вставить("id"        , 1);
    Запись1.Вставить("timestamp" , ТекущаяДата);
    Запись1.Вставить("user_id"   , 100);
    Запись1.Вставить("event_type", "click");
    Запись1.Вставить("payload"   , "{}");

    Запись2 = Новый Структура;
    Запись2.Вставить("id"        , 2);
    Запись2.Вставить("timestamp" , ТекущаяДата);
    Запись2.Вставить("user_id"   , 200);
    Запись2.Вставить("event_type", "hover");
    Запись2.Вставить("payload"   , "{}");

    МассивДанных.Добавить(Запись1);
    МассивДанных.Добавить(Запись2);

    Мета = Новый Массив;
    Мета.Добавить(Новый Структура("name,type", "id"        , "UInt64"));
    Мета.Добавить(Новый Структура("name,type", "timestamp" , "DateTime"));
    Мета.Добавить(Новый Структура("name,type", "user_id"   , "UInt32"));
    Мета.Добавить(Новый Структура("name,type", "event_type", "String"));
    Мета.Добавить(Новый Структура("name,type", "payload"   , "String"));

    Данные     = Новый Структура("meta,data", Мета, МассивДанных);
    БазаДанных = "default";
    IDЗапроса  = Строка(Новый УникальныйИдентификатор());

    Запрос    = OPI_ClickHouse.ПолучитьНастройкиЗапроса(ТекстЗапроса, БазаДанных, IDЗапроса, Данные, ФорматДанных);
    Результат = OPI_ClickHouse.ВыполнитьЗапрос(Соединение, Запрос);

    // Запрос с внешней таблицей

    ИмяТаблицы       = "ext_users";
    СтруктураКолонок = Новый Структура;
    СтруктураКолонок.Вставить("id"  , "UInt64");
    СтруктураКолонок.Вставить("name", "String");

    Таб           = Символы.Таб;
    ДанныеТаблицы = "1" + Таб + "John
    |2" + Таб + "Jane
    |3" + Таб + "Bob";

    ВнешняяТаблица = OPI_ClickHouse.ПолучитьСтруктуруВнешнейТаблицы(ИмяТаблицы, СтруктураКолонок, ДанныеТаблицы, "TSV");

    МассивВнешнихТаблиц = Новый Массив;
    МассивВнешнихТаблиц.Добавить(ВнешняяТаблица);

    ТекстЗапроса = "SELECT * FROM ext_users WHERE id > 1";

    Запрос    = OPI_ClickHouse.ПолучитьНастройкиЗапроса(ТекстЗапроса, , , , "JSON", МассивВнешнихТаблиц);
    Результат = OPI_ClickHouse.ВыполнитьЗапрос(Соединение, Запрос);

    // Выборка

    ТекстВыборки = "SELECT * FROM events";

    Запрос    = OPI_ClickHouse.ПолучитьНастройкиЗапроса(ТекстВыборки, , , , "JSON");
    Результат = OPI_ClickHouse.ВыполнитьЗапрос(Соединение, Запрос);
```
    

 <Tabs>
  
    <TabItem value="bash" label="Bash" default>
        ```bash
            # JSON данные также могут быть переданы как путь к файлу .json
            
            oint clickhouse ВыполнитьЗапрос \
              --conn "{'address':'http://127.0.0.1:9101','proto':{'main.proto':'/* This file describes gRPC protocol supported in ClickHouse.\n *\n * To use this protocol a client should send one or more messages of the QueryInfo type\n * and then receive one or more messages of the Result type.\n * According to that the service provides four methods for that:\n * ExecuteQuery(QueryInfo) returns (Result)\n * ExecuteQueryWithStreamInput(stream QueryInfo) returns (Result)\n * ExecuteQueryWithStreamOutput(QueryInfo) returns (stream Result)\n * ExecuteQueryWithStreamIO(stream QueryInfo) returns (stream Result)\n * It\u0027s up to the client to choose which method to use.\n * For example, ExecuteQueryWithStreamInput() allows the client to add data multiple times\n * while executing a query, which is suitable for inserting many rows.\n */\n\nsyntax = \"proto3\";\n\npackage clickhouse.grpc;\n\nmessage NameAndType {\n   string name = 1;\n   string type = 2;\n}\n\n// Describes an external table - a table which will exists only while a query is executing.\nmessage ExternalTable {\n   // Name of the table. If omitted, \"_data\" is used.\n   string name = 1;\n\n   // Columns of the table. Types are required, names can be omitted. If the names are omitted, \"_1\", \"_2\", ... is used.\n   repeated NameAndType columns = 2;\n\n   // Data to insert to the external table.\n   // If a method with streaming input (i.e. ExecuteQueryWithStreamInput() or ExecuteQueryWithStreamIO()) is used,\n   // then data for insertion to the same external table can be split between multiple QueryInfos.\n   bytes data = 3;\n\n   // Format of the data to insert to the external table.\n   string format = 4;\n\n   // Compression type used to compress `data`.\n   // Supported values: none, gzip(gz), deflate, brotli(br), lzma(xz), zstd(zst), lz4, bz2.\n   string compression_type = 6;\n\n   // Settings for executing that insertion, applied after QueryInfo.settings.\n   map<string, string> settings = 5;\n}\n\nmessage ObsoleteTransportCompression {\n   enum CompressionAlgorithm {\n      NO_COMPRESSION = 0;\n      DEFLATE = 1;\n      GZIP = 2;\n      STREAM_GZIP = 3;\n   }\n   enum CompressionLevel {\n      COMPRESSION_NONE = 0;\n      COMPRESSION_LOW = 1;\n      COMPRESSION_MEDIUM = 2;\n      COMPRESSION_HIGH = 3;\n   }\n   CompressionAlgorithm algorithm = 1;\n   CompressionLevel level = 2;\n}\n\n// Information about a query which a client sends to a ClickHouse server.\n// The first QueryInfo can set any of the following fields. Extra QueryInfos only add extra data.\n// In extra QueryInfos only `input_data`, `external_tables`, `next_query_info` and `cancel` fields can be set.\nmessage QueryInfo {\n   string query = 1;\n   string query_id = 2;\n   map<string, string> settings = 3;\n\n   // Default database.\n   string database = 4;\n\n   // Input data, used both as data for INSERT query and as data for the input() function.\n   bytes input_data = 5;\n\n   // Delimiter for input_data, inserted between input_data from adjacent QueryInfos.\n   bytes input_data_delimiter = 6;\n\n   // Default output format. If not specified, \u0027TabSeparated\u0027 is used.\n   string output_format = 7;\n\n   // Set it if you want the names and the types of output columns to be sent to the client.\n   bool send_output_columns = 24;\n\n   repeated ExternalTable external_tables = 8;\n\n   string user_name = 9;\n   string password = 10;\n   string quota = 11;\n   string jwt = 25;\n\n   // Works exactly like sessions in the HTTP protocol.\n   string session_id = 12;\n   bool session_check = 13;\n   uint32 session_timeout = 14;\n\n   // Set `cancel` to true to stop executing the query.\n   bool cancel = 15;\n\n   // If true there will be at least one more QueryInfo in the input stream.\n   // `next_query_info` is allowed to be set only if a method with streaming input (i.e. ExecuteQueryWithStreamInput() or ExecuteQueryWithStreamIO()) is used.\n   bool next_query_info = 16;\n\n   // Compression type for `input_data`.\n   // Supported compression types: none, gzip(gz), deflate, brotli(br), lzma(xz), zstd(zst), lz4, bz2.\n   // The client is responsible to compress data before putting it into `input_data`.\n   string input_compression_type = 20;\n\n   // Compression type for `output_data`, `totals` and `extremes`.\n   // Supported compression types: none, gzip(gz), deflate, brotli(br), lzma(xz), zstd(zst), lz4, bz2.\n   // The client receives compressed data and should decompress it by itself.\n   // Consider also setting `output_compression_level`.\n   string output_compression_type = 21;\n\n   // Compression level.\n   // WARNING: If it\u0027s not specified the compression level is set to zero by default which might be not the best choice for some compression types (see below).\n   // The compression level should be in the following range (the higher the number, the better the compression):\n   // none: compression level isn\u0027t used\n   // gzip: 0..9; 0 means no compression, 6 is recommended by default (compression level -1 also means 6)\n   // brotli: 0..11\n   // lzma: 0..9; 6 is recommended by default\n   // zstd: 1..22; 3 is recommended by default (compression level 0 also means 3)\n   // lz4: 0..16; values < 0 mean fast acceleration\n   // bz2: 1..9\n   int32 output_compression_level = 19;\n\n   // Transport compression is an alternative way to make the server to compress its response.\n   // This kind of compression implies that instead of compressing just `output` the server will compress whole packed messages of the `Result` type,\n   // and then gRPC implementation on client side will decompress those messages so client code won\u0027t be bothered with decompression.\n   // Here is a big difference between the transport compression and the compression enabled by setting `output_compression_type` because\n   // in case of the transport compression the client code receives already decompressed data in `output`.\n   // If the transport compression is not set here it can still be enabled by the server configuration.\n   // Supported compression types: none, deflate, gzip, stream_gzip\n   // Supported compression levels: 0..3\n   // WARNING: Don\u0027t set `transport_compression` and `output_compression` at the same time because it will make the server to compress its output twice!\n   string transport_compression_type = 22;\n   int32 transport_compression_level = 23;\n\n   /// Obsolete fields, should not be used in new code.\n   ObsoleteTransportCompression obsolete_result_compression = 17;\n   string obsolete_compression_type = 18;\n}\n\nenum LogsLevel {\n   LOG_NONE = 0;\n   LOG_FATAL = 1;\n   LOG_CRITICAL = 2;\n   LOG_ERROR = 3;\n   LOG_WARNING = 4;\n   LOG_NOTICE = 5;\n   LOG_INFORMATION = 6;\n   LOG_DEBUG = 7;\n   LOG_TRACE = 8;\n}\n\nmessage LogEntry {\n   uint32 time = 1;\n   uint32 time_microseconds = 2;\n   uint64 thread_id = 3;\n   string query_id = 4;\n   LogsLevel level = 5;\n   string source = 6;\n   string text = 7;\n}\n\nmessage Progress {\n   uint64 read_rows = 1;\n   uint64 read_bytes = 2;\n   uint64 total_rows_to_read = 3;\n   uint64 written_rows = 4;\n   uint64 written_bytes = 5;\n}\n\nmessage Stats {\n   uint64 rows = 1;\n   uint64 blocks = 2;\n   uint64 allocated_bytes = 3;\n   bool applied_limit = 4;\n   uint64 rows_before_limit = 5;\n   bool applied_aggregation = 6;\n   uint64 rows_before_aggregation = 7;\n}\n\nmessage Exception {\n   int32 code = 1;\n   string name = 2;\n   string display_text = 3;\n   string stack_trace = 4;\n}\n\n// Result of execution of a query which is sent back by the ClickHouse server to the client.\nmessage Result {\n   string query_id = 9;\n   string time_zone = 10;\n\n   // The format in which `output`, `totals` and `extremes` are written.\n   // It\u0027s either the same as `output_format` specified in `QueryInfo` or the format specified in the query itself.\n   string output_format = 11;\n\n   // The names and types of columns of the result written in `output`.\n   repeated NameAndType output_columns = 12;\n\n   // Output of the query, represented in the `output_format`.\n   bytes output = 1;\n   bytes totals = 2;\n   bytes extremes = 3;\n\n   repeated LogEntry logs = 4;\n   Progress progress = 5;\n   Stats stats = 6;\n\n   // Set by the ClickHouse server if there was an exception thrown while executing.\n   Exception exception = 7;\n\n   // Set by the ClickHouse server if executing was cancelled by the `cancel` field in QueryInfo.\n   bool cancelled = 8;\n}\n\nservice ClickHouse {\n   rpc ExecuteQuery(QueryInfo) returns (Result) {}\n   rpc ExecuteQueryWithStreamInput(stream QueryInfo) returns (Result) {}\n   rpc ExecuteQueryWithStreamOutput(QueryInfo) returns (stream Result) {}\n   rpc ExecuteQueryWithStreamIO(stream QueryInfo) returns (stream Result) {}\n}'}}" \
              --req "{'query':'SELECT * FROM ext_grpc','format':'JSON','external_tables':[{'name':'ext_grpc','cols':{'id':'UInt64','name':'String'},'data':'1\tJohn\n2\tJane','format':'TSV'}]}"
        ```
    </TabItem>
  
    <TabItem value="bat" label="CMD/Bat" default>
        ```batch
            :: JSON данные также могут быть переданы как путь к файлу .json
            
            oint clickhouse ВыполнитьЗапрос ^
              --conn "{'address':'http://127.0.0.1:9101','proto':{'main.proto':'/* This file describes gRPC protocol supported in ClickHouse.\n *\n * To use this protocol a client should send one or more messages of the QueryInfo type\n * and then receive one or more messages of the Result type.\n * According to that the service provides four methods for that:\n * ExecuteQuery(QueryInfo) returns (Result)\n * ExecuteQueryWithStreamInput(stream QueryInfo) returns (Result)\n * ExecuteQueryWithStreamOutput(QueryInfo) returns (stream Result)\n * ExecuteQueryWithStreamIO(stream QueryInfo) returns (stream Result)\n * It\u0027s up to the client to choose which method to use.\n * For example, ExecuteQueryWithStreamInput() allows the client to add data multiple times\n * while executing a query, which is suitable for inserting many rows.\n */\n\nsyntax = \"proto3\";\n\npackage clickhouse.grpc;\n\nmessage NameAndType {\n   string name = 1;\n   string type = 2;\n}\n\n// Describes an external table - a table which will exists only while a query is executing.\nmessage ExternalTable {\n   // Name of the table. If omitted, \"_data\" is used.\n   string name = 1;\n\n   // Columns of the table. Types are required, names can be omitted. If the names are omitted, \"_1\", \"_2\", ... is used.\n   repeated NameAndType columns = 2;\n\n   // Data to insert to the external table.\n   // If a method with streaming input (i.e. ExecuteQueryWithStreamInput() or ExecuteQueryWithStreamIO()) is used,\n   // then data for insertion to the same external table can be split between multiple QueryInfos.\n   bytes data = 3;\n\n   // Format of the data to insert to the external table.\n   string format = 4;\n\n   // Compression type used to compress `data`.\n   // Supported values: none, gzip(gz), deflate, brotli(br), lzma(xz), zstd(zst), lz4, bz2.\n   string compression_type = 6;\n\n   // Settings for executing that insertion, applied after QueryInfo.settings.\n   map<string, string> settings = 5;\n}\n\nmessage ObsoleteTransportCompression {\n   enum CompressionAlgorithm {\n      NO_COMPRESSION = 0;\n      DEFLATE = 1;\n      GZIP = 2;\n      STREAM_GZIP = 3;\n   }\n   enum CompressionLevel {\n      COMPRESSION_NONE = 0;\n      COMPRESSION_LOW = 1;\n      COMPRESSION_MEDIUM = 2;\n      COMPRESSION_HIGH = 3;\n   }\n   CompressionAlgorithm algorithm = 1;\n   CompressionLevel level = 2;\n}\n\n// Information about a query which a client sends to a ClickHouse server.\n// The first QueryInfo can set any of the following fields. Extra QueryInfos only add extra data.\n// In extra QueryInfos only `input_data`, `external_tables`, `next_query_info` and `cancel` fields can be set.\nmessage QueryInfo {\n   string query = 1;\n   string query_id = 2;\n   map<string, string> settings = 3;\n\n   // Default database.\n   string database = 4;\n\n   // Input data, used both as data for INSERT query and as data for the input() function.\n   bytes input_data = 5;\n\n   // Delimiter for input_data, inserted between input_data from adjacent QueryInfos.\n   bytes input_data_delimiter = 6;\n\n   // Default output format. If not specified, \u0027TabSeparated\u0027 is used.\n   string output_format = 7;\n\n   // Set it if you want the names and the types of output columns to be sent to the client.\n   bool send_output_columns = 24;\n\n   repeated ExternalTable external_tables = 8;\n\n   string user_name = 9;\n   string password = 10;\n   string quota = 11;\n   string jwt = 25;\n\n   // Works exactly like sessions in the HTTP protocol.\n   string session_id = 12;\n   bool session_check = 13;\n   uint32 session_timeout = 14;\n\n   // Set `cancel` to true to stop executing the query.\n   bool cancel = 15;\n\n   // If true there will be at least one more QueryInfo in the input stream.\n   // `next_query_info` is allowed to be set only if a method with streaming input (i.e. ExecuteQueryWithStreamInput() or ExecuteQueryWithStreamIO()) is used.\n   bool next_query_info = 16;\n\n   // Compression type for `input_data`.\n   // Supported compression types: none, gzip(gz), deflate, brotli(br), lzma(xz), zstd(zst), lz4, bz2.\n   // The client is responsible to compress data before putting it into `input_data`.\n   string input_compression_type = 20;\n\n   // Compression type for `output_data`, `totals` and `extremes`.\n   // Supported compression types: none, gzip(gz), deflate, brotli(br), lzma(xz), zstd(zst), lz4, bz2.\n   // The client receives compressed data and should decompress it by itself.\n   // Consider also setting `output_compression_level`.\n   string output_compression_type = 21;\n\n   // Compression level.\n   // WARNING: If it\u0027s not specified the compression level is set to zero by default which might be not the best choice for some compression types (see below).\n   // The compression level should be in the following range (the higher the number, the better the compression):\n   // none: compression level isn\u0027t used\n   // gzip: 0..9; 0 means no compression, 6 is recommended by default (compression level -1 also means 6)\n   // brotli: 0..11\n   // lzma: 0..9; 6 is recommended by default\n   // zstd: 1..22; 3 is recommended by default (compression level 0 also means 3)\n   // lz4: 0..16; values < 0 mean fast acceleration\n   // bz2: 1..9\n   int32 output_compression_level = 19;\n\n   // Transport compression is an alternative way to make the server to compress its response.\n   // This kind of compression implies that instead of compressing just `output` the server will compress whole packed messages of the `Result` type,\n   // and then gRPC implementation on client side will decompress those messages so client code won\u0027t be bothered with decompression.\n   // Here is a big difference between the transport compression and the compression enabled by setting `output_compression_type` because\n   // in case of the transport compression the client code receives already decompressed data in `output`.\n   // If the transport compression is not set here it can still be enabled by the server configuration.\n   // Supported compression types: none, deflate, gzip, stream_gzip\n   // Supported compression levels: 0..3\n   // WARNING: Don\u0027t set `transport_compression` and `output_compression` at the same time because it will make the server to compress its output twice!\n   string transport_compression_type = 22;\n   int32 transport_compression_level = 23;\n\n   /// Obsolete fields, should not be used in new code.\n   ObsoleteTransportCompression obsolete_result_compression = 17;\n   string obsolete_compression_type = 18;\n}\n\nenum LogsLevel {\n   LOG_NONE = 0;\n   LOG_FATAL = 1;\n   LOG_CRITICAL = 2;\n   LOG_ERROR = 3;\n   LOG_WARNING = 4;\n   LOG_NOTICE = 5;\n   LOG_INFORMATION = 6;\n   LOG_DEBUG = 7;\n   LOG_TRACE = 8;\n}\n\nmessage LogEntry {\n   uint32 time = 1;\n   uint32 time_microseconds = 2;\n   uint64 thread_id = 3;\n   string query_id = 4;\n   LogsLevel level = 5;\n   string source = 6;\n   string text = 7;\n}\n\nmessage Progress {\n   uint64 read_rows = 1;\n   uint64 read_bytes = 2;\n   uint64 total_rows_to_read = 3;\n   uint64 written_rows = 4;\n   uint64 written_bytes = 5;\n}\n\nmessage Stats {\n   uint64 rows = 1;\n   uint64 blocks = 2;\n   uint64 allocated_bytes = 3;\n   bool applied_limit = 4;\n   uint64 rows_before_limit = 5;\n   bool applied_aggregation = 6;\n   uint64 rows_before_aggregation = 7;\n}\n\nmessage Exception {\n   int32 code = 1;\n   string name = 2;\n   string display_text = 3;\n   string stack_trace = 4;\n}\n\n// Result of execution of a query which is sent back by the ClickHouse server to the client.\nmessage Result {\n   string query_id = 9;\n   string time_zone = 10;\n\n   // The format in which `output`, `totals` and `extremes` are written.\n   // It\u0027s either the same as `output_format` specified in `QueryInfo` or the format specified in the query itself.\n   string output_format = 11;\n\n   // The names and types of columns of the result written in `output`.\n   repeated NameAndType output_columns = 12;\n\n   // Output of the query, represented in the `output_format`.\n   bytes output = 1;\n   bytes totals = 2;\n   bytes extremes = 3;\n\n   repeated LogEntry logs = 4;\n   Progress progress = 5;\n   Stats stats = 6;\n\n   // Set by the ClickHouse server if there was an exception thrown while executing.\n   Exception exception = 7;\n\n   // Set by the ClickHouse server if executing was cancelled by the `cancel` field in QueryInfo.\n   bool cancelled = 8;\n}\n\nservice ClickHouse {\n   rpc ExecuteQuery(QueryInfo) returns (Result) {}\n   rpc ExecuteQueryWithStreamInput(stream QueryInfo) returns (Result) {}\n   rpc ExecuteQueryWithStreamOutput(QueryInfo) returns (stream Result) {}\n   rpc ExecuteQueryWithStreamIO(stream QueryInfo) returns (stream Result) {}\n}'}}" ^
              --req "{'query':'SELECT * FROM ext_grpc','format':'JSON','external_tables':[{'name':'ext_grpc','cols':{'id':'UInt64','name':'String'},'data':'1\tJohn\n2\tJane','format':'TSV'}]}"
        ```
    </TabItem>
</Tabs>


```json title="Результат"
{
 "status": 200,
 "result": true,
 "body": {
  "meta": [
   {
    "name": "id",
    "type": "UInt64"
   },
   {
    "name": "value",
    "type": "String"
   }
  ],
  "data": [
   {
    "id": "1",
    "value": "test1"
   },
   {
    "id": "2",
    "value": "test2"
   }
  ],
  "rows": 2,
  "statistics": {
   "elapsed": 0.00086055,
   "rows_read": 2,
   "bytes_read": 44
  }
 },
 "headers": {
  "Date": "Fri, 06 Feb 2026 10:55:25 GMT",
  "Connection": "Keep-Alive",
  "X-ClickHouse-Server-Display-Name": "clickhouse",
  "Transfer-Encoding": "chunked",
  "X-ClickHouse-Query-Id": "7ae62e4e-8a3b-4eff-8eb6-ffc869fda55e",
  "X-ClickHouse-Format": "JSON",
  "X-ClickHouse-Timezone": "Europe/Moscow",
  "Keep-Alive": "timeout=3",
  "X-ClickHouse-Summary": "{\"read_rows\":\"2\",\"read_bytes\":\"44\",\"written_rows\":\"0\",\"written_bytes\":\"0\",\"total_rows_to_read\":\"0\",\"result_rows\":\"0\",\"result_bytes\":\"0\"}",
  "Content-Type": "application/json; charset=UTF-8"
 }
}
```
