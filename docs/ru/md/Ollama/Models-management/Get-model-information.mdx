---
sidebar_position: 3
description: Получить информацию о модели и другие функции для работы с Ollama в Открытом пакете интеграций - бесплатной open-source библиотеке интеграций для 1С:Предприятие 8, OneScript и CLI
keywords: [1C, 1С, 1С:Предприятие, 1С:Предприятие 8.3, API, Интеграция, Сервисы, Обмен, OneScript, CLI, Ollama]
---

import Tabs from '@theme/Tabs';
import TabItem from '@theme/TabItem';

# Получить информацию о модели
 Получает информацию о выбранной модели



`Функция ПолучитьИнформациюОМодели(Знач URL, Знач Модель, Знач Подробно = Истина, Знач ДопЗаголовки = "") Экспорт`

  | Параметр | CLI опция | Тип | Обяз. | Назначение |
  |-|-|-|-|-|
  | URL | --url | Строка | &#x2714; | URL сервера Ollama |
  | Модель | --model | Строка | &#x2714; | Имя модели |
  | Подробно | --verbose | Булево | &#x2716; | Возврат полной информации о модели |
  | ДопЗаголовки | --headers | Соответствие Из КлючИЗначение | &#x2716; | Доп заголовки запроса, если необходимо |

  
  Возвращаемое значение:   Соответствие Из КлючИЗначение - Результат обработки

:::tip
Метод в документации API: [Show Model Information](https://github.com/ollama/ollama/blob/main/docs/api.md#show-model-information)
:::
<br/>


```bsl title="Пример использования для 1С:Предприятие/OneScript"
    URL   = "https://hut.openintegrations.dev/ollama";
    Токен = "12We34..."; // Авторизация - не часть API Ollama

    Модель = "mario";

    ДопЗаголовки = Новый Соответствие;
    ДопЗаголовки.Вставить("Authorization", СтрШаблон("Bearer %1", Токен));

    Результат = OPI_Ollama.ПолучитьИнформациюОМодели(URL, Модель, Ложь, ДопЗаголовки);
```
    

 <Tabs>
  
    <TabItem value="bash" label="Bash" default>
        ```bash
            # JSON данные также могут быть переданы как путь к файлу .json
            
            oint ollama ПолучитьИнформациюОМодели \
              --url "https://hut.openintegrations.dev/ollama" \
              --model "mario" \
              --verbose false \
              --headers "{'Authorization':'***'}"
        ```
    </TabItem>
  
    <TabItem value="bat" label="CMD/Bat" default>
        ```batch
            :: JSON данные также могут быть переданы как путь к файлу .json
            
            oint ollama ПолучитьИнформациюОМодели ^
              --url "https://hut.openintegrations.dev/ollama" ^
              --model "mario" ^
              --verbose false ^
              --headers "{'Authorization':'***'}"
        ```
    </TabItem>
</Tabs>


```json title="Результат"
{
 "modelfile": "# Modelfile generated by \"ollama show\"\n# To build a new Modelfile based on this, replace FROM with:\n# FROM mario:latest\n\nFROM /root/.ollama/models/blobs/sha256-2af3b81862c6be03c769683af18efdadb2c33f60ff32ab6f83e42c043d6c7816\nTEMPLATE \"<|system|>\n{{ .System }}</s>\n<|user|>\n{{ .Prompt }}</s>\n<|assistant|>\n\"\nSYSTEM You are Mario from Super Mario Bros.\nPARAMETER stop <|system|>\nPARAMETER stop <|user|>\nPARAMETER stop <|assistant|>\nPARAMETER stop </s>\n",
 "parameters": "stop                           \"<|system|>\"\nstop                           \"<|user|>\"\nstop                           \"<|assistant|>\"\nstop                           \"</s>\"",
 "template": "<|system|>\n{{ .System }}</s>\n<|user|>\n{{ .Prompt }}</s>\n<|assistant|>\n",
 "system": "You are Mario from Super Mario Bros.",
 "details": {
  "parent_model": "tinyllama:latest",
  "format": "gguf",
  "family": "llama",
  "families": [
   "***"
  ],
  "parameter_size": "1.1B",
  "quantization_level": "Q4_0"
 },
 "model_info": {
  "general.architecture": "llama",
  "general.file_type": 2,
  "general.parameter_count": 1100048384,
  "general.quantization_version": 2,
  "llama.attention.head_count": 32,
  "llama.attention.head_count_kv": 4,
  "llama.attention.layer_norm_rms_epsilon": 0.00001,
  "llama.block_count": 22,
  "llama.context_length": 2048,
  "llama.embedding_length": 2048,
  "llama.feed_forward_length": 5632,
  "llama.rope.dimension_count": 64,
  "llama.rope.freq_base": 10000,
  "tokenizer.ggml.bos_token_id": "***",
  "tokenizer.ggml.eos_token_id": "***",
  "tokenizer.ggml.merges": "***",
  "tokenizer.ggml.model": "***",
  "tokenizer.ggml.padding_token_id": "***",
  "tokenizer.ggml.scores": "***",
  "tokenizer.ggml.token_type": "***",
  "tokenizer.ggml.tokens": "***",
  "tokenizer.ggml.unknown_token_id": "***"
 },
 "tensors": [
  {
   "name": "output.weight",
   "type": "Q6_K",
   "shape": [
    "***",
    "***"
   ]
  },
  {
   "name": "token_embd.weight",
   "type": "Q4_0",
   "shape": [
    "***",
    "***"
   ]
  },
  {
   "name": "blk.0.attn_norm.weight",
   "type": "F32",
   "shape": [
    "***"
   ]
  },
  {
   "name": "blk.0.ffn_down.weight",
   "type": "Q4_0",
   "shape": [
    "***",
    "***"
   ]
  },
  {
   "name": "blk.0.ffn_gate.weight",
   "type": "Q4_0",
   "shape": [
    "***",
    "***"
   ]
  },
  {
   "name": "blk.0.ffn_up.weight",
   "type": "Q4_0",
   "shape": [
    "***",
    "***"
   ]
  },
  {
   "name": "blk.0.ffn_norm.weight",
   "type": "F32",
   "shape": [
    "***"
   ]
  },
  {
   "name": "blk.0.attn_k.weight",
   "type": "Q4_0",
   "shape": [
    "***",
    "***"
   ]
  },
  {
   "name": "blk.0.attn_output.weight",
   "type": "Q4_0",
   "shape": [
    "***",
    "***"
   ]
  },
  {
   "name": "blk.0.attn_q.weight",
   "type": "Q4_0",
   "shape": [
    "***",
    "***"
   ]
  },
  {
   "name": "blk.0.attn_v.weight",
   "type": "Q4_0",
   "shape": [
    "***",
    "***"
   ]
  },
  {
   "name": "blk.1.attn_norm.weight",
   "type": "F32",
   "shape": [
    "***"
   ]
  },
  {
   "name": "blk.1.ffn_down.weight",
   "type": "Q4_0",
   "shape": [
    "***",
    "***"
   ]
  },
  {
   "name": "blk.1.ffn_gate.weight",
   "type": "Q4_0",
   "shape": [
    "***",
    "***"
   ]
  },
  {
...
```
